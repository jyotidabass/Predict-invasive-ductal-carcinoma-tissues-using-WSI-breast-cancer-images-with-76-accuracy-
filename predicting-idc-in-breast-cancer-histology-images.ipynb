{"metadata":{"language_info":{"file_extension":".py","nbconvert_exporter":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","version":"3.6.3","name":"python"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Predicting IDC in Breast Cancer Histology Images**\n\nBreast cancer is the most common form of cancer in women, and invasive ductal carcinoma (IDC) is the most common form of breast cancer.  Accurately identifying and categorizing breast cancer subtypes is an important clinical task, and automated methods can be used to save time and reduce error.\n\nThe goal of this script is to identify IDC when it is present in otherwise unlabeled histopathology images.  The dataset consists of approximately five thousand 50x50 pixel RGB digital images of H&E-stained breast histopathology samples that are labeled as either IDC or non-IDC. These numpy arrays are small patches that were extracted from digital images of breast tissue samples.  The breast tissue contains many cells but only some of them are cancerous.  Patches that are labeled \"1\" contain cells that are characteristic of invasive ductal carcinoma.  For more information about the data, see https://www.ncbi.nlm.nih.gov/pubmed/27563488 and http://spie.org/Publications/Proceedings/Paper/10.1117/12.2043872.\n\nFor more information about IDC and breast cancer, please review the following publications: \n* https://www.ncbi.nlm.nih.gov/pubmed/27864452\n* https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3893344/\n* https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4952020/","metadata":{"_uuid":"1f9069e7a456e3c1a75f148234f6433076305a76","_cell_guid":"080fa63d-2ad7-4702-a972-61dfa453872c"}},{"cell_type":"markdown","source":"*Step 1: Import Modules*","metadata":{"_uuid":"d96e080ca9ca3f1ded5f4432286f80a31a32fe5a","_cell_guid":"9104593b-f406-449d-9feb-dc5baa146db7"}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pylab as plt\nfrom scipy.misc import imresize, imread\nimport itertools\nimport sklearn\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nimport keras\nfrom keras import backend as K\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential, model_from_json\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\nfrom keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D\n%matplotlib inline","metadata":{"_kg_hide-input":true,"_uuid":"5fda999ecf2c3e94831ac467dd96fabf2d5a9401","_cell_guid":"8114fd92-8576-41f7-b636-698011a0ada4"},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"*Step 2: Load Data*","metadata":{"_uuid":"0693c954882cb02125f00973f93772edc93ee275","_cell_guid":"c281e7a5-5d0a-4c19-b5d1-a0364ce7276b"}},{"cell_type":"code","source":"X = np.load('../input/X.npy') # images\nY = np.load('../input/Y.npy') # labels associated to images (0 = no IDC, 1 = IDC)","metadata":{"_uuid":"1cca29752ae8ff62de50236aebcdc091bd446619","_cell_guid":"488707f3-c33c-42db-8344-47353b21e931","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"*Step 3: Describe Data*","metadata":{"_uuid":"19734095c942f5844d42b149d6ce93e67dae620d","_cell_guid":"a6881bc4-94d2-450c-b70a-840f6b43548b"}},{"cell_type":"code","source":"def describeData(a,b):\n    print('Total number of images: {}'.format(len(a)))\n    print('Number of IDC(-) Images: {}'.format(np.sum(b==0)))\n    print('Number of IDC(+) Images: {}'.format(np.sum(b==1)))\n    print('Percentage of positive images: {:.2f}%'.format(100*np.mean(b)))\n    print('Image shape (Width, Height, Channels): {}'.format(a[0].shape))\ndescribeData(X,Y)","metadata":{"_uuid":"f67d30bd2c4fea8ced7a707ba71fa1931ec286e3","_cell_guid":"192003f3-4bb1-45a9-b0ac-86b136079d56"},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"*Step 4: Plot Data*","metadata":{"_uuid":"61009c6bb13abf77fbe27aba4c8499392d560824","_cell_guid":"e55339c8-7b35-40be-9662-e7c071b06cbd"}},{"cell_type":"code","source":"imgs0 = X[Y==0] # (0 = no IDC, 1 = IDC)\nimgs1 = X[Y==1] \n\ndef plotOne(a,b):\n    \"\"\"\n    Plot one numpy array\n    \"\"\"\n    plt.subplot(1,2,1)\n    plt.title('IDC (-)')\n    plt.imshow(a[100])\n    plt.subplot(1,2,2)\n    plt.title('IDC (+)')\n    plt.imshow(b[100])\nplotOne(imgs0, imgs1) \n","metadata":{"_uuid":"26019e32a32b341c49a214c7b23babc474752df6","_cell_guid":"fc47fb16-21df-456e-a20c-882bd7127279"},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def plotTwo(a,b): \n    \"\"\"\n    Plot a bunch of numpy arrays sorted by label\n    \"\"\"\n    for row in range(3):\n        plt.figure(figsize=(20, 10))\n        for col in range(3):\n            plt.subplot(1,8,col+1)\n            plt.title('IDC (-)')\n            plt.imshow(a[row+col])\n            plt.axis('off')       \n            plt.subplot(1,8,col+4)\n            plt.title('IDC (+)')\n            plt.imshow(b[row+col])\n            plt.axis('off')\nplotTwo(imgs0, imgs1) \n","metadata":{"_uuid":"1aa10060590ed9357971c2f2ca2404faa7bc1824","_cell_guid":"b45be80f-4901-47ac-8f9f-2689d57f6a99"},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"*Step 4: Preprocess Data*","metadata":{"_uuid":"17f99516ccbfc1ff9817fdce0a8481b172e8af20","_cell_guid":"a32f0573-5081-4d53-8b67-b1e19b8e4b25"}},{"cell_type":"code","source":"def plotHistogram(a):\n    \"\"\"\n    Plot histogram of RGB Pixel Intensities\n    \"\"\"\n    plt.figure(figsize=(10,5))\n    plt.subplot(1,2,1)\n    plt.imshow(a)\n    plt.axis('off')\n    plt.title('IDC(+)' if Y[1] else 'IDC(-)')\n    histo = plt.subplot(1,2,2)\n    histo.set_ylabel('Count')\n    histo.set_xlabel('Pixel Intensity')\n    n_bins = 30\n    plt.hist(a[:,:,0].flatten(), bins= n_bins, lw = 0, color='r', alpha=0.5);\n    plt.hist(a[:,:,1].flatten(), bins= n_bins, lw = 0, color='g', alpha=0.5);\n    plt.hist(a[:,:,2].flatten(), bins= n_bins, lw = 0, color='b', alpha=0.5);\nplotHistogram(X[100])","metadata":{"_uuid":"587bb44d8c9b1028f882f600b5cfc8fbf1504aea","_cell_guid":"59bda880-1d34-424f-be00-12531ec84999"},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"The data is scaled from 0 to 256 but we want it to be scaled from 0 to 1.  This will make the data compatible with a wide variety of different classification algorithms.\n\nWe also want to set aside 20% of the data for k-fold cross-validation testing.  This will make the trained model less prone to overfitting.","metadata":{"_uuid":"37b8f4cdca6e8d3687555eb69e41ae49ebb7cde7","_cell_guid":"191233d4-e313-49c5-9277-806dd71e131b"}},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n\n# Reduce Sample Size for DeBugging\nX_train = X_train[0:30000] \nY_train = Y_train[0:30000]\nX_test = X_test[0:30000] \nY_test = Y_test[0:30000]\n\n# Normalize the data\nX_train = X_train / 256.0\nX_test = X_test / 256.0\n\nprint(\"Training Data Shape:\", X_train.shape, X_train.shape)\nprint(\"Testing Data Shape:\", X_test.shape, X_test.shape)\n","metadata":{"_uuid":"59fcd56ba5ae49065ef3143163e7001d7d00103d","_cell_guid":"5d3cdc63-c803-4f41-8f90-665ca03a7506"},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"plotHistogram(X_train[100])","metadata":{"_uuid":"941926042260afe7e4be9ae287f4e938c064cc04","_cell_guid":"c09f56fa-5483-4139-8ae2-a47cebe25ff8"},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Now the data is scaled from 0 to 1.\n\nNext we can try using some standard classification algorithms to predict whether or not IDC is present in each given sample.","metadata":{"_uuid":"5cf87765a3e101e012ae347a3b27f23ebecedf36","_cell_guid":"8e0a97eb-3d6e-45a2-b675-fc2cdb1f41b0"}},{"cell_type":"markdown","source":"*Step 5: Evaluate Classification Algorithms*","metadata":{"_uuid":"9efaee02b056d85e32411114195ade342a2f8f37","_cell_guid":"f2edc92a-e89b-48d9-9ac8-5cd6b3699476"}},{"cell_type":"code","source":"# Make Data 1D for compatability with standard classifiers\n\nX_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\nX_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]\n\nX_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\nX_testFlat = X_test.reshape(X_test.shape[0], X_testShape)","metadata":{"_uuid":"5756fb439fcfa7555c6d39c075d81b2aa1742b97","_cell_guid":"08b866bb-e9f7-4bd8-8950-b009d91cfbfa","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#runLogisticRegression\ndef runLogisticRegression(a,b,c,d):\n    \"\"\"Run LogisticRegression w/ Kfold CV\"\"\"\n    model = LogisticRegression()\n    model.fit(a,b)\n    kfold = model_selection.KFold(n_splits=10)\n    accuracy = model_selection.cross_val_score(model, c,d, cv=kfold, scoring='accuracy')\n    mean = accuracy.mean() \n    stdev = accuracy.std()\n    print('LogisticRegression - Training set accuracy: %s (%s)' % (mean, stdev))\n    print('')\nrunLogisticRegression(X_trainFlat, Y_train, X_testFlat, Y_test)","metadata":{"_uuid":"adbb109329a9298ac50779ad652d2626a4eecb68","_cell_guid":"e592d39a-f2ef-4fc7-b098-7d8e033f1566"},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Compare Performance of Classification Algorithms\ndef compareABunchOfDifferentModelsAccuracy(a,b,c,d):\n    \"\"\"\n    compare performance of classifiers on X_train, X_test, Y_train, Y_test\n    http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score\n    http://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score\n    \"\"\"    \n    print('')\n    print('Compare Multiple Classifiers:')\n    print('')\n    print('K-Fold Cross-Validation Accuracy:')\n    print('')\n    models = []\n    models.append(('LR', LogisticRegression()))\n    models.append(('RF', RandomForestClassifier()))\n    models.append(('KNN', KNeighborsClassifier()))\n    models.append(('SVM', SVC()))\n    models.append(('LSVM', LinearSVC()))\n    models.append(('GNB', GaussianNB()))\n    models.append(('DTC', DecisionTreeClassifier()))\n    #models.append(('GBC', GradientBoostingClassifier()))\n    #models.append(('LDA', LinearDiscriminantAnalysis()))       \n    resultsAccuracy = []\n    names = []\n    for name, model in models:\n        model.fit(a, b)\n        kfold = model_selection.KFold(n_splits=10)\n        accuracy_results = model_selection.cross_val_score(model, c, d, cv=kfold, scoring='accuracy')\n        resultsAccuracy.append(accuracy_results)\n        names.append(name)\n        accuracyMessage = \"%s: %f (%f)\" % (name, accuracy_results.mean(), accuracy_results.std())\n        print(accuracyMessage)  \n    # boxplot algorithm comparison\n    fig = plt.figure()\n    fig.suptitle('Algorithm Comparison: Accuracy')\n    ax = fig.add_subplot(111)\n    plt.boxplot(resultsAccuracy)\n    ax.set_xticklabels(names)\n    ax.set_ylabel('Cross-Validation: Accuracy Score')\n    plt.show()\n    return\ncompareABunchOfDifferentModelsAccuracy(X_trainFlat, Y_train, X_testFlat, Y_test)\n\n\ndef defineModels():\n    \"\"\"\n    This function just defines each abbreviation used in the previous function (e.g. LR = Logistic Regression)\n    \"\"\"\n    print('')\n    print('LR = LogisticRegression')\n    print('RF = RandomForestClassifier')\n    print('KNN = KNeighborsClassifier')\n    print('SVM = Support Vector Machine SVC')\n    print('LSVM = LinearSVC')\n    print('GNB = GaussianNB')\n    print('DTC = DecisionTreeClassifier')\n    #print('GBC = GradientBoostingClassifier')\n    #print('LDA = LinearDiscriminantAnalysis')\n    print('')\n    return\ndefineModels()","metadata":{"_uuid":"64ab48ac6f2feeb7f96b2df0e40f585bf3b94320","_cell_guid":"687a8785-824d-4b37-a739-deff752a5dc9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the Support Vector Machine we are getting ~75% accuracy. Next I will plot a confusion matrix for the results that were produced by the Support Vector Machine in order to verify that we do not have too many false positives.  I will also plot a learning curve to see if our model is overfitting or if our model has high bias.","metadata":{"_uuid":"c0dce9fa7ba1b2e22370e320affe7847cbce559c","_cell_guid":"8946daa7-fa21-4922-953f-28e67596351f"}},{"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Plots a learning curve. http://scikit-learn.org/stable/modules/learning_curve.html\n    \"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n    plt.legend(loc=\"best\")\n    return plt\n\ndef plotLotsOfLearningCurves(a,b):\n    \"\"\"Plot a bunch of learning curves http://scikit-learn.org/stable/modules/learning_curve.html\"\"\"\n    models = []\n    models.append(('Support Vector Machine', SVC()))\n    for name, model in models:\n        plot_learning_curve(model, 'Learning Curve For %s Classifier'% (name), a,b, (0.5,1), 10)\nplotLotsOfLearningCurves(X_trainFlat, Y_train)","metadata":{"_uuid":"447cdc390ee5518448fd181022a13bdca1f3a49f","_cell_guid":"8dd4e3e2-2523-4651-8976-70f60036693e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Look at confusion matrix \ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (5,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n#Run SVC w/ Confusion Matrix\ndef runSVCconfusion(a,b,c,d):\n    \"\"\"Run SVC w/ Kfold CV + Confusion Matrix\"\"\"\n    model = SVC()\n    model.fit(a, b)\n    prediction = model.predict(c)\n    kfold = model_selection.KFold(n_splits=10)\n    accuracy = model_selection.cross_val_score(model, c,d, cv=kfold, scoring='accuracy')\n    mean = accuracy.mean() \n    stdev = accuracy.std()\n    print('\\nSupport Vector Machine - Training set accuracy: %s (%s)' % (mean, stdev),\"\\n\")\n    cnf_matrix = confusion_matrix(d, prediction)\n    np.set_printoptions(precision=2)\n    class_names = [\"Diagnosis\" \"IDC(-)\", \"Diagnosis\" \"IDC(+)\"]\n    plt.figure()\n    plot_confusion_matrix(cnf_matrix, classes=class_names,\n                          title='Confusion matrix, without normalization')\n    plt.figure()\n    plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n                          title='Normalized confusion matrix')\n    plt.show()\nrunSVCconfusion(X_trainFlat, Y_train, X_testFlat, Y_test)","metadata":{"_uuid":"4495b5c20e77ec309b3efaa72e721ae13668f590","_cell_guid":"077a7197-fbd6-4447-8492-402aaf9bf3b5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here in these confusion plots the Y-Axis represents the True labels [\"IDC(-)\" or \"IDC(+)\"] while the X-Axis represents the Predicted labels (generated by the Support Vector Machine).  Ideally, the predicted labels will be the same as the idea labels.  This is actually pretty good!  But on the learning curve you can see that the training score tracks very closely to the cross-validation score and this makes me suspicious that the model might be overfitting.  And anyways... we should be able to improve our model's accuracy by using neural networks.  Next I will use the original 2-D data and I will try to solve this classification problem by using 2D convolutional neural networks.","metadata":{"_uuid":"1c8c3724812719457cc7f72435e07b3e3ed5fe22","_cell_guid":"08fbc2c0-38fe-4781-bea8-3ceb0c2cb599"}},{"cell_type":"code","source":"# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_train = to_categorical(Y_train, num_classes = 2)\nY_test = to_categorical(Y_test, num_classes = 2)","metadata":{"_uuid":"c693af7e9f5d9b993f7a0b8dc8d5a8ccc7d21fd7","_cell_guid":"d6663fb1-7a6c-444b-a052-9a190fedf4d2","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Special callback to see learning curves\nclass MetricsCheckpoint(Callback):\n    \"\"\"Callback that saves metrics after each epoch\"\"\"\n    def __init__(self, savepath):\n        super(MetricsCheckpoint, self).__init__()\n        self.savepath = savepath\n        self.history = {}\n    def on_epoch_end(self, epoch, logs=None):\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        np.save(self.savepath, self.history)\n\ndef plotKerasLearningCurve():\n    plt.figure(figsize=(10,5))\n    metrics = np.load('logs.npy')[()]\n    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n        l = np.array(metrics[k])\n        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n        y = l[x]\n        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n    plt.legend(loc=4)\n    plt.axis([0, None, None, None]);\n    plt.grid()\n    plt.xlabel('Number of epochs')\n","metadata":{"_uuid":"b4269b87124dac817d0d424f7a99f5f4bd3d18c4","_cell_guid":"876bdd91-a49b-45d6-b06d-da33ceed6388","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def runKerasCNN(a,b,c,d):\n    \"\"\"\n    https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n    \"\"\"\n    batch_size = 128\n    num_classes = 2\n    epochs = 12  \n    img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n    input_shape = (img_rows, img_cols, 3)\n    x_train = a\n    y_train = b\n    x_test = c\n    y_test = d   \n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=(3, 3),\n                     activation='relu',\n                     input_shape=input_shape))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer=keras.optimizers.Adadelta(),\n                  metrics=['accuracy'])\n    model.fit(x_train, y_train,\n              batch_size=batch_size,\n              verbose=1,\n              epochs=epochs,\n              validation_data=(x_test, y_test),callbacks = [MetricsCheckpoint('logs')])\n    score = model.evaluate(x_test, y_test, verbose=0)\n    print('\\nKeras CNN #1A - accuracy:', score[1],'\\n')\n    y_pred = model.predict(c) \n    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')\n    Y_pred_classes = np.argmax(y_pred,axis = 1) \n    Y_true = np.argmax(Y_test,axis = 1) \n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values())) \nrunKerasCNN(X_train, Y_train,  X_test, Y_test)\nplotKerasLearningCurve()","metadata":{"_uuid":"157e713a4f734314cd96b2adb85c391c3afff433","_cell_guid":"433ec78e-1dce-4b38-a0ff-d4da7d57a5a3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The confusion matrix illustrates that this model is predicting IDC(+) too often and the learning curve illustrates that the validation score is consistently less than the traning score.  Together, these results suggest that our model may have some bias.\n\nI will try using different artificial neural network.\n","metadata":{"_uuid":"346cfe785b2f4b8803ce3e77184108ca52c67bd5","_cell_guid":"26da5d07-8cc0-41c5-b5e9-c8e3ded1e1a7"}},{"cell_type":"code","source":"def runAnotherKeras(a, b,c,d):\n    # my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out   \n    batch_size = 128\n    num_classes = 2\n    epochs = 12\n    # input image dimensions\n    img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n    input_shape = (img_rows, img_cols, 3)\n    model = Sequential()\n    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu', input_shape = input_shape))\n    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.25))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu'))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.25))\n    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu'))\n    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    #model.add(Dense(1024, activation = \"relu\"))\n    #model.add(Dropout(0.5))\n    model.add(Dense(512, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation = \"softmax\"))\n    optimizer = RMSprop(lr=0.001, decay=1e-6)\n    model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n    model.fit(a,b,\n                  batch_size=batch_size,\n                  verbose=1,\n                  epochs=epochs,\n                  validation_data=(c,d),callbacks = [MetricsCheckpoint('logs')])\n    score = model.evaluate(c,d, verbose=0)\n    print('\\nKeras CNN #2 - accuracy:', score[1], '\\n')\n    y_pred = model.predict(c)\n    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='') \n    Y_pred_classes = np.argmax(y_pred,axis = 1) \n    Y_true = np.argmax(Y_test,axis = 1) \n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values())) \nrunAnotherKeras(X_train, Y_train, X_test, Y_test)\nplotKerasLearningCurve()","metadata":{"_uuid":"8c6eb55d9654d901fe380bc6232db0f0d4ac4bcb","_cell_guid":"6b5f37c6-a1cc-4648-9239-d81e97cb3514"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The confusion matrix illustrates that this model is predicting IDC(-) too often and the learning curve illustrates that the validation score is consistently less than the traning score.  Together, these results suggest that our model suffers from high bias.\n\nI will try using another network architecture and I will also include a data augmentation step in our to try to decrease the bias in our model.","metadata":{"_uuid":"a999917f98d8f4fdf3a51c3921789b62835dc3b7","_cell_guid":"d669f339-35c9-4f5f-b308-97398762bf27"}},{"cell_type":"code","source":"def kerasAugmentation(a,b,c,d):\n    img_rows, img_cols = 50,50\n    input_shape = (img_rows, img_cols, 3)\n    batch_size = 128\n    num_classes = 2\n    epochs = 12\n    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n    model.add(Activation('relu'))\n    model.add(Conv2D(32, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n    model.add(Conv2D(64, (3, 3), padding='same'))\n    model.add(Activation('relu'))\n    model.add(Conv2D(64, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n    model.add(Conv2D(256, (3, 3), padding='same')) \n    model.add(Activation('relu'))\n    model.add(Conv2D(256, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(1024))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n    opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n    datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n    datagen.fit(a)\n    model.fit_generator(datagen.flow(a,b, batch_size=32),\n                        steps_per_epoch=len(a) / 32, epochs=epochs, validation_data = [c, d],callbacks = [MetricsCheckpoint('logs')])\n    score = model.evaluate(c,d, verbose=0)\n    print('\\nKeras CNN #3B - accuracy:', score[1],'\\n')\n    y_pred = model.predict(c)\n    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')\n    Y_pred_classes = np.argmax(y_pred,axis = 1) \n    Y_true = np.argmax(Y_test,axis = 1) \n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values())) \nkerasAugmentation(X_train, Y_train, X_test, Y_test)\nplotKerasLearningCurve()","metadata":{"_uuid":"067e0665da108abfa3dacd4353bcacd1ca22de2a","_cell_guid":"eec880dd-086f-4c0b-88af-fbdaa58fd2c7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This model picked IDC(+) every single time which suggests a high bias, but the learning curve suggests that there maybe some overfitting.  Either way, this model will not work.\n\nI will try another model now where I change the network architecture but retain the data augmentation step.","metadata":{"_uuid":"3f554740068badd620841101fde68f808cd52c24","_cell_guid":"5bd1f3fd-3996-48b1-8e49-db820e99721e"}},{"cell_type":"code","source":"def runAnotherKerasAugmentedConfusion(a,b,c,d):\n    # my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out \n    batch_size = 128\n    num_classes = 2\n    epochs = 16\n    img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n    input_shape = (img_rows, img_cols, 3)\n    model = Sequential() \n    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu', input_shape = input_shape))\n    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.25))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu'))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.25))\n    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu'))\n    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    #model.add(Dense(1024, activation = \"relu\"))\n    #model.add(Dropout(0.5))\n    model.add(Dense(512, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation = \"softmax\"))\n    optimizer = RMSprop(lr=0.001, decay=1e-6)\n    model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n    datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n    datagen.fit(a)\n    model.fit_generator(datagen.flow(a,b, batch_size=32),steps_per_epoch=len(a) / 32, epochs=epochs, validation_data = [c, d],callbacks = [MetricsCheckpoint('logs')])\n    score = model.evaluate(c,d, verbose=0)\n    print('\\nKeras CNN #2B - accuracy:', score[1],'\\n')\n    y_pred = model.predict(c)\n    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')    \n    Y_pred_classes = np.argmax(y_pred,axis = 1) \n    Y_true = np.argmax(Y_test,axis = 1) \n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values())) \nrunAnotherKerasAugmentedConfusion(X_train, Y_train, X_test, Y_test)   \nplotKerasLearningCurve()","metadata":{"_uuid":"d0ae41a9906bfa3a441c3249516739f2c4baa908","_cell_guid":"b7b17a1a-b7b3-4abc-a812-f2f6b60c0a88"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The confusion matrix illustrates that this model is predicting IDC(-) far too often and the learning curve illustrates that the validation score is consistently less than the traning score.  Together, these results suggest that our model suffers from high bias despite containing a data augmentation step.\n\nI will try using another network architecture.","metadata":{"_uuid":"45c5124c1d6630edc2614cfbd88b1ea5160b3991","_cell_guid":"9f80503f-90fa-4e20-9eea-b15245abc9ce"}},{"cell_type":"code","source":"# Create the model\ndef yetAnotherKeras(a,b,c,d):\n    model = Sequential()\n    model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(50, 50, 3))) # first layer : convolution\n    model.add(MaxPooling2D(pool_size=(3, 3))) # second layer : pooling (reduce the size of the image per 3) \n    model.add(Conv2D(32, (5, 5), activation='relu')) \n    model.add(MaxPooling2D(pool_size=(3, 3)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation='sigmoid')) # output 1 value between 0 and 1 : probability to have cancer\n    model.summary()\n    model.compile(loss=keras.losses.binary_crossentropy, # Use binary crossentropy as a loss function  \n                  optimizer=keras.optimizers.Adam(),\n                  metrics=['accuracy'])\n    model.fit(a,b,\n              batch_size=128,\n              epochs=12,\n              verbose=1,\n              validation_data = [c,d],\n            callbacks = [MetricsCheckpoint('logs')])\n    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n    y_pred = model.predict(c)\n    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')\n    Y_pred_classes = np.argmax(y_pred,axis = 1) \n    Y_true = np.argmax(Y_test,axis = 1) \n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values())) \nyetAnotherKeras(X_train,Y_train,X_test,Y_test)\nplotKerasLearningCurve()","metadata":{"_uuid":"848f4e4f7466c72c32af7fbb4c33d145815497f0","_cell_guid":"2f4c1341-37d2-4a60-a9ba-98c48f4227db"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is a decent result.  The learning curve here suggests that our model does not have too much bias.  If anything, the model may be overfitting a bit, given the close relationship between the training and validation scores.\n\nI will try using a different network architecture and once again I will also include a data augmentation step.","metadata":{"_uuid":"3986ecf8f6c17056d455b0af1d1847a996ef7695","_cell_guid":"318e5e72-6608-4256-be7d-0a4974ba6320"}},{"cell_type":"code","source":"def runKerasCNNAugment(a,b,c,d):\n    \"\"\"\n    Run Keras CNN: https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n    \"\"\"\n    batch_size = 128\n    num_classes = 2\n    epochs = 12\n    img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n    input_shape = (img_rows, img_cols, 3)\n    x_train = a\n    y_train = b\n    x_test = c\n    y_test = d\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=(3, 3),\n                     activation='relu',\n                     input_shape=input_shape))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer=keras.optimizers.Adadelta(),\n                  metrics=['accuracy'])\n    datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n    model.fit_generator(datagen.flow(a,b, batch_size=32),\n                        steps_per_epoch=len(a) / 32, epochs=epochs, validation_data = [c, d],callbacks = [MetricsCheckpoint('logs')])\n    score = model.evaluate(c,d, verbose=0)\n    print('\\nKeras CNN #1C - accuracy:', score[1],'\\n')\n    y_pred = model.predict(c)\n    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')    \n    score = model.evaluate(x_test, y_test, verbose=0)\n    Y_pred_classes = np.argmax(y_pred,axis = 1) \n    Y_true = np.argmax(Y_test,axis = 1) \n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values())) \nrunKerasCNNAugment(X_train, Y_train,  X_test, Y_test)\nplotKerasLearningCurve()","metadata":{"_uuid":"6c318102474676d0d33a1a89e877ee02cfd790df","_cell_guid":"37f23b9b-4089-412b-89a4-56339f68931c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is our best result yet.  76% accuracy and a distribution of predicted labels that is similar to the distribtion of actual labels (50/50).   The learning curve suggests that there is not too much overfitting given the different shapes of the training and cross-validation curves, and both the confusion matrix and the learning curve suggest that the model does not have high bias.  But with only two categories (IDC negative/IDC plus), we should hope to do better than 80% accuracy.  Soon I will experiment with different data augmentation approaches in an attempt to improve our model's accuracy. In the future, tools like this can be used to save time, cut costs, and increase the accuracy of imaging-based diagnostic approaches in the healthcare industry. ","metadata":{"_uuid":"d14cbbce7cde54c5381c5c2ec0a96aad3af66297","_cell_guid":"9bf36145-0148-4be6-8ac8-f1d42d48c776"}},{"cell_type":"markdown","source":"To Do:\n1) Improve data visualization\n2) Optimize data augmentation\n3) Optimize NN architecture","metadata":{"_uuid":"2d6ac5ecb8fb75f40f1ba67a957fe536f2af8f2b","_cell_guid":"ce2339ef-12f5-4fa7-8a0f-27a766502e33"}}]}